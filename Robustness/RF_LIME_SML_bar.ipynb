{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from adversarial_models import * \n",
    "from utils import *\n",
    "from get_data import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Reducing Normal rows\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "['Denial of Service', 'Port Scanning', 'None']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = Params(\"model_configurations/experiment_params.json\")\n",
    "np.random.seed(params.seed)\n",
    "X, y, cols = get_and_preprocess_simargl(params)\n",
    "\n",
    "# Add a random column -- this is what we'll have LIME/SHAP explain.\n",
    "X['unrelated_column'] = np.random.choice([0,1],size=X.shape[0])\n",
    "features = [c for c in X]\n",
    "\n",
    "categorical_feature_name = ['L4_DST_PORT','TCP_WIN_MSS_IN',\n",
    "                            'OUT_PKTS','IN_PKTS', \n",
    "                            'unrelated_column']\n",
    "\n",
    "# categorical_feature_name = [' Init_Win_bytes_backward',\n",
    "#                             ' Destination Port',' Fwd Packet Length Std',\n",
    "#                             ' Flow IAT Max','Total Length of Fwd Packets', \n",
    "#                             'unrelated_column']\n",
    "\n",
    "categorical_feature_indcs = [features.index(c) for c in categorical_feature_name]\n",
    "\n",
    "race_indc = features.index('FLOW_DURATION_MILLISECONDS')\n",
    "unrelated_indcs = features.index('unrelated_column')\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class racist_model_f:\n",
    "    # Decision rule: classify negatively if race is black\n",
    "    def predict(self,X):\n",
    "        return np.array([params.negative_outcome if x[race_indc] > 0 else params.positive_outcome for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)\n",
    "    \n",
    "class innocuous_model_psi:\n",
    "    # Decision rule: classify according to randomly drawn column 'unrelated column'\n",
    "    def predict(self,X):\n",
    "        return np.array([params.negative_outcome if x[unrelated_indcs] > 0 else params.positive_outcome for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and normalize\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y)\n",
    "xtest_not_normalized = deepcopy(xtest)\n",
    "ss = StandardScaler().fit(xtrain)\n",
    "xtrain = ss.transform(xtrain)\n",
    "xtest = ss.transform(xtest)\n",
    "\n",
    "# Train the adversarial model for LIME with f and psi \n",
    "adv_lime = Adversarial_Lime_Model(racist_model_f(), innocuous_model_psi()).\\\n",
    "            train(xtrain, ytrain, feature_names=features, categorical_features=categorical_feature_indcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "real value [1]\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "predicted value 0\n",
      "------------------------------------------------------------------\n",
      "Explanation on biased f:\n",
      " [('FLOW_DURATION_MILLISECONDS', -0.4498381718460197), ('TCP_WIN_MSS_IN=0', -0.01562008458767036), ('IN_PKTS=0', 0.005219339619458634)] \n",
      "\n",
      "\n",
      "Explanation on adversarial model:\n",
      " [('unrelated_column=1', -0.9986907022249827), ('TCP_WIN_MSS_IN=0', 5.663238981128991e-05), ('L4_DST_PORT=0', -3.355311827348114e-05)] \n",
      "\n",
      "Prediction fidelity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Let's just look at a the first example in the test set\n",
    "ex_indc = np.random.choice(xtest.shape[0])\n",
    "# print(xtest.shape[0])\n",
    "indices = np.where(ytest == 1)\n",
    "index_positions = indices[0]\n",
    "# print(index_positions)\n",
    "ex_indc = index_positions[0]\n",
    "# To get a baseline, we'll look at LIME applied to the biased model f\n",
    "normal_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(),\n",
    "                                                          discretize_continuous=False,\n",
    "                                                          categorical_features=categorical_feature_indcs)\n",
    "\n",
    "normal_exp = normal_explainer.explain_instance(xtest[ex_indc], racist_model_f().predict_proba).as_list()\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "print('real value', ytest[ex_indc:ex_indc+1])\n",
    "# print(ytest)\n",
    "print('------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------')\n",
    "# print(xtest[ex_indc])\n",
    "# print(xtest)\n",
    "print('predicted value', racist_model_f().predict(xtest)[ex_indc])\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# pred = racist_model_f().predict_proba(xtest[ex_indc])                             \n",
    "# print('prediction', pred)\n",
    "print (\"Explanation on biased f:\\n\",normal_exp[:3],\"\\n\\n\")\n",
    "\n",
    "# Now, lets look at the explanations on the adversarial model \n",
    "adv_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(), \n",
    "                                                       discretize_continuous=False,\n",
    "                                                       categorical_features=categorical_feature_indcs)\n",
    "\n",
    "adv_exp = adv_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba).as_list()\n",
    "\n",
    "print (\"Explanation on adversarial model:\\n\",adv_exp[:3],\"\\n\")\n",
    "\n",
    "print(\"Prediction fidelity: {0:3.2}\".format(adv_lime.fidelity(xtest[ex_indc:ex_indc+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 buckets, 3 graphs\n",
    "dict_biased_1 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}\n",
    "dict_biased_2 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}\n",
    "dict_biased_3 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}\n",
    "attack_1 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}\n",
    "\n",
    "attack_2 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}\n",
    "\n",
    "attack_3 = {\n",
    "    'Biased': 0,\n",
    "    'Unrelated_1':0,\n",
    "    'Unrelated_2':0,\n",
    "    'Others':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features analyzed\n",
    "biased_feature = 'FLOW_DURATION_MILLISECONDS'\n",
    "Unrelated_1_feature = 'unrelated_column'\n",
    "# Unrelated_2_feature = 'unrelated_column'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress 0.1 %\n",
      "progress 0.2 %\n",
      "progress 0.3 %\n",
      "progress 0.4 %\n",
      "progress 0.5 %\n",
      "progress 0.6 %\n",
      "progress 0.7000000000000001 %\n",
      "progress 0.8 %\n",
      "progress 0.8999999999999999 %\n",
      "progress 1.0 %\n",
      "progress 1.0999999999999999 %\n",
      "progress 1.2 %\n",
      "progress 1.3 %\n",
      "progress 1.4000000000000001 %\n",
      "progress 1.5 %\n",
      "progress 1.6 %\n",
      "progress 1.7000000000000002 %\n",
      "progress 1.7999999999999998 %\n",
      "progress 1.9 %\n",
      "progress 2.0 %\n",
      "progress 2.1 %\n",
      "progress 2.1999999999999997 %\n",
      "progress 2.3 %\n",
      "progress 2.4 %\n",
      "progress 2.5 %\n",
      "progress 2.6 %\n",
      "progress 2.7 %\n",
      "progress 2.8000000000000003 %\n",
      "progress 2.9000000000000004 %\n",
      "progress 3.0 %\n",
      "progress 3.1 %\n",
      "progress 3.2 %\n",
      "progress 3.3000000000000003 %\n",
      "progress 3.4000000000000004 %\n",
      "progress 3.5000000000000004 %\n",
      "progress 3.5999999999999996 %\n",
      "progress 3.6999999999999997 %\n",
      "progress 3.8 %\n",
      "progress 3.9 %\n",
      "progress 4.0 %\n",
      "progress 4.1000000000000005 %\n",
      "progress 4.2 %\n",
      "progress 4.3 %\n",
      "progress 4.3999999999999995 %\n",
      "progress 4.5 %\n",
      "progress 4.6 %\n",
      "progress 4.7 %\n",
      "progress 4.8 %\n",
      "progress 4.9 %\n",
      "progress 5.0 %\n",
      "progress 5.1 %\n",
      "progress 5.2 %\n",
      "progress 5.3 %\n",
      "progress 5.4 %\n",
      "progress 5.5 %\n",
      "progress 5.6000000000000005 %\n",
      "progress 5.7 %\n",
      "progress 5.800000000000001 %\n",
      "progress 5.8999999999999995 %\n",
      "progress 6.0 %\n",
      "progress 6.1 %\n",
      "progress 6.2 %\n",
      "progress 6.3 %\n",
      "progress 6.4 %\n",
      "progress 6.5 %\n",
      "progress 6.6000000000000005 %\n",
      "progress 6.7 %\n",
      "progress 6.800000000000001 %\n",
      "progress 6.9 %\n",
      "progress 7.000000000000001 %\n",
      "progress 7.1 %\n",
      "progress 7.199999999999999 %\n",
      "progress 7.3 %\n",
      "progress 7.3999999999999995 %\n",
      "progress 7.5 %\n",
      "progress 7.6 %\n",
      "progress 7.7 %\n",
      "progress 7.8 %\n",
      "progress 7.9 %\n",
      "progress 8.0 %\n",
      "progress 8.1 %\n",
      "progress 8.200000000000001 %\n",
      "progress 8.3 %\n",
      "progress 8.4 %\n",
      "progress 8.5 %\n",
      "progress 8.6 %\n",
      "progress 8.7 %\n",
      "progress 8.799999999999999 %\n",
      "progress 8.9 %\n",
      "progress 9.0 %\n",
      "progress 9.1 %\n",
      "progress 9.2 %\n",
      "progress 9.3 %\n",
      "progress 9.4 %\n",
      "progress 9.5 %\n",
      "progress 9.6 %\n",
      "progress 9.700000000000001 %\n",
      "progress 9.8 %\n",
      "progress 9.9 %\n",
      "progress 10.0 %\n",
      "progress 10.100000000000001 %\n",
      "progress 10.2 %\n",
      "progress 10.299999999999999 %\n",
      "progress 10.4 %\n",
      "progress 10.5 %\n",
      "progress 10.6 %\n",
      "progress 10.7 %\n",
      "progress 10.8 %\n",
      "progress 10.9 %\n",
      "progress 11.0 %\n",
      "progress 11.1 %\n",
      "progress 11.200000000000001 %\n",
      "progress 11.3 %\n",
      "progress 11.4 %\n",
      "progress 11.5 %\n",
      "progress 11.600000000000001 %\n",
      "progress 11.700000000000001 %\n",
      "progress 11.799999999999999 %\n",
      "progress 11.899999999999999 %\n",
      "progress 12.0 %\n",
      "progress 12.1 %\n",
      "progress 12.2 %\n",
      "progress 12.3 %\n",
      "progress 12.4 %\n",
      "progress 12.5 %\n",
      "progress 12.6 %\n",
      "progress 12.7 %\n",
      "progress 12.8 %\n",
      "progress 12.9 %\n",
      "progress 13.0 %\n",
      "progress 13.100000000000001 %\n",
      "progress 13.200000000000001 %\n",
      "progress 13.3 %\n",
      "progress 13.4 %\n",
      "progress 13.5 %\n",
      "progress 13.600000000000001 %\n",
      "progress 13.700000000000001 %\n",
      "progress 13.8 %\n",
      "progress 13.900000000000002 %\n",
      "progress 14.000000000000002 %\n",
      "progress 14.099999999999998 %\n",
      "progress 14.2 %\n",
      "progress 14.299999999999999 %\n",
      "progress 14.399999999999999 %\n",
      "progress 14.499999999999998 %\n",
      "progress 14.6 %\n",
      "progress 14.7 %\n",
      "progress 14.799999999999999 %\n",
      "progress 14.899999999999999 %\n",
      "progress 15.0 %\n",
      "progress 15.1 %\n",
      "progress 15.2 %\n",
      "progress 15.299999999999999 %\n",
      "progress 15.4 %\n",
      "progress 15.5 %\n",
      "progress 15.6 %\n",
      "progress 15.7 %\n",
      "progress 15.8 %\n",
      "progress 15.9 %\n",
      "progress 16.0 %\n",
      "progress 16.1 %\n",
      "progress 16.2 %\n",
      "progress 16.3 %\n",
      "progress 16.400000000000002 %\n",
      "progress 16.5 %\n",
      "progress 16.6 %\n",
      "progress 16.7 %\n",
      "progress 16.8 %\n",
      "progress 16.900000000000002 %\n",
      "progress 17.0 %\n",
      "progress 17.1 %\n",
      "progress 17.2 %\n",
      "progress 17.299999999999997 %\n",
      "progress 17.4 %\n",
      "progress 17.5 %\n",
      "progress 17.599999999999998 %\n",
      "progress 17.7 %\n",
      "progress 17.8 %\n",
      "progress 17.9 %\n",
      "progress 18.0 %\n",
      "progress 18.099999999999998 %\n",
      "progress 18.2 %\n",
      "progress 18.3 %\n",
      "progress 18.4 %\n",
      "progress 18.5 %\n",
      "progress 18.6 %\n",
      "progress 18.7 %\n",
      "progress 18.8 %\n",
      "progress 18.9 %\n",
      "progress 19.0 %\n",
      "progress 19.1 %\n",
      "progress 19.2 %\n",
      "progress 19.3 %\n",
      "progress 19.400000000000002 %\n",
      "progress 19.5 %\n",
      "progress 19.6 %\n",
      "progress 19.7 %\n",
      "progress 19.8 %\n",
      "progress 19.900000000000002 %\n",
      "progress 20.0 %\n",
      "progress 20.1 %\n",
      "progress 20.200000000000003 %\n",
      "progress 20.3 %\n",
      "progress 20.4 %\n",
      "progress 20.5 %\n",
      "progress 20.599999999999998 %\n",
      "progress 20.7 %\n",
      "progress 20.8 %\n",
      "progress 20.9 %\n",
      "progress 21.0 %\n",
      "progress 21.099999999999998 %\n",
      "progress 21.2 %\n",
      "progress 21.3 %\n",
      "progress 21.4 %\n",
      "progress 21.5 %\n",
      "progress 21.6 %\n",
      "progress 21.7 %\n",
      "progress 21.8 %\n",
      "progress 21.9 %\n",
      "progress 22.0 %\n",
      "progress 22.1 %\n",
      "progress 22.2 %\n",
      "progress 22.3 %\n",
      "progress 22.400000000000002 %\n",
      "progress 22.5 %\n",
      "progress 22.6 %\n",
      "progress 22.7 %\n",
      "progress 22.8 %\n",
      "progress 22.900000000000002 %\n",
      "progress 23.0 %\n",
      "progress 23.1 %\n",
      "progress 23.200000000000003 %\n",
      "progress 23.3 %\n",
      "progress 23.400000000000002 %\n",
      "progress 23.5 %\n",
      "progress 23.599999999999998 %\n",
      "progress 23.7 %\n",
      "progress 23.799999999999997 %\n",
      "progress 23.9 %\n",
      "progress 24.0 %\n",
      "progress 24.099999999999998 %\n",
      "progress 24.2 %\n",
      "progress 24.3 %\n",
      "progress 24.4 %\n",
      "progress 24.5 %\n",
      "progress 24.6 %\n",
      "progress 24.7 %\n",
      "progress 24.8 %\n",
      "progress 24.9 %\n",
      "progress 25.0 %\n",
      "progress 25.1 %\n",
      "progress 25.2 %\n",
      "progress 25.3 %\n",
      "progress 25.4 %\n",
      "progress 25.5 %\n",
      "progress 25.6 %\n",
      "progress 25.7 %\n",
      "progress 25.8 %\n",
      "progress 25.900000000000002 %\n",
      "progress 26.0 %\n",
      "progress 26.1 %\n",
      "progress 26.200000000000003 %\n",
      "progress 26.3 %\n",
      "progress 26.400000000000002 %\n",
      "progress 26.5 %\n",
      "progress 26.6 %\n",
      "progress 26.700000000000003 %\n",
      "progress 26.8 %\n",
      "progress 26.900000000000002 %\n",
      "progress 27.0 %\n",
      "progress 27.1 %\n",
      "progress 27.200000000000003 %\n",
      "progress 27.3 %\n",
      "progress 27.400000000000002 %\n",
      "progress 27.500000000000004 %\n",
      "progress 27.6 %\n",
      "progress 27.700000000000003 %\n",
      "progress 27.800000000000004 %\n",
      "progress 27.900000000000002 %\n",
      "progress 28.000000000000004 %\n",
      "progress 28.1 %\n",
      "progress 28.199999999999996 %\n",
      "progress 28.299999999999997 %\n",
      "progress 28.4 %\n",
      "progress 28.499999999999996 %\n",
      "progress 28.599999999999998 %\n",
      "progress 28.7 %\n",
      "progress 28.799999999999997 %\n",
      "progress 28.9 %\n",
      "progress 28.999999999999996 %\n",
      "progress 29.099999999999998 %\n",
      "progress 29.2 %\n",
      "progress 29.299999999999997 %\n",
      "progress 29.4 %\n",
      "progress 29.5 %\n",
      "progress 29.599999999999998 %\n",
      "progress 29.7 %\n",
      "progress 29.799999999999997 %\n",
      "progress 29.9 %\n",
      "progress 30.0 %\n",
      "progress 30.099999999999998 %\n",
      "progress 30.2 %\n",
      "progress 30.3 %\n",
      "progress 30.4 %\n",
      "progress 30.5 %\n",
      "progress 30.599999999999998 %\n",
      "progress 30.7 %\n",
      "progress 30.8 %\n",
      "progress 30.9 %\n",
      "progress 31.0 %\n",
      "progress 31.1 %\n",
      "progress 31.2 %\n",
      "progress 31.3 %\n",
      "progress 31.4 %\n",
      "progress 31.5 %\n",
      "progress 31.6 %\n",
      "progress 31.7 %\n",
      "progress 31.8 %\n",
      "progress 31.900000000000002 %\n",
      "progress 32.0 %\n",
      "progress 32.1 %\n",
      "progress 32.2 %\n",
      "progress 32.300000000000004 %\n",
      "progress 32.4 %\n",
      "progress 32.5 %\n",
      "progress 32.6 %\n",
      "progress 32.7 %\n",
      "progress 32.800000000000004 %\n",
      "progress 32.9 %\n",
      "progress 33.0 %\n",
      "progress 33.1 %\n",
      "progress 33.2 %\n",
      "progress 33.300000000000004 %\n",
      "progress 33.4 %\n",
      "progress 33.5 %\n",
      "progress 33.6 %\n",
      "progress 33.7 %\n",
      "progress 33.800000000000004 %\n",
      "progress 33.900000000000006 %\n",
      "progress 34.0 %\n",
      "progress 34.1 %\n",
      "progress 34.2 %\n",
      "progress 34.300000000000004 %\n",
      "progress 34.4 %\n",
      "progress 34.5 %\n",
      "progress 34.599999999999994 %\n",
      "progress 34.699999999999996 %\n",
      "progress 34.8 %\n",
      "progress 34.9 %\n",
      "progress 35.0 %\n",
      "progress 35.099999999999994 %\n",
      "progress 35.199999999999996 %\n",
      "progress 35.3 %\n",
      "progress 35.4 %\n",
      "progress 35.5 %\n",
      "progress 35.6 %\n",
      "progress 35.699999999999996 %\n",
      "progress 35.8 %\n",
      "progress 35.9 %\n",
      "progress 36.0 %\n",
      "progress 36.1 %\n",
      "progress 36.199999999999996 %\n",
      "progress 36.3 %\n",
      "progress 36.4 %\n",
      "progress 36.5 %\n",
      "progress 36.6 %\n",
      "progress 36.7 %\n",
      "progress 36.8 %\n",
      "progress 36.9 %\n",
      "progress 37.0 %\n",
      "progress 37.1 %\n",
      "progress 37.2 %\n",
      "progress 37.3 %\n",
      "progress 37.4 %\n",
      "progress 37.5 %\n",
      "progress 37.6 %\n",
      "progress 37.7 %\n",
      "progress 37.8 %\n",
      "progress 37.9 %\n",
      "progress 38.0 %\n",
      "progress 38.1 %\n",
      "progress 38.2 %\n",
      "progress 38.3 %\n",
      "progress 38.4 %\n",
      "progress 38.5 %\n",
      "progress 38.6 %\n",
      "progress 38.7 %\n",
      "progress 38.800000000000004 %\n",
      "progress 38.9 %\n",
      "progress 39.0 %\n",
      "progress 39.1 %\n",
      "progress 39.2 %\n",
      "progress 39.300000000000004 %\n",
      "progress 39.4 %\n",
      "progress 39.5 %\n",
      "progress 39.6 %\n",
      "progress 39.7 %\n",
      "progress 39.800000000000004 %\n",
      "progress 39.900000000000006 %\n",
      "progress 40.0 %\n",
      "progress 40.1 %\n",
      "progress 40.2 %\n",
      "progress 40.300000000000004 %\n",
      "progress 40.400000000000006 %\n",
      "progress 40.5 %\n",
      "progress 40.6 %\n",
      "progress 40.699999999999996 %\n",
      "progress 40.8 %\n",
      "progress 40.9 %\n",
      "progress 41.0 %\n",
      "progress 41.099999999999994 %\n",
      "progress 41.199999999999996 %\n",
      "progress 41.3 %\n",
      "progress 41.4 %\n",
      "progress 41.5 %\n",
      "progress 41.6 %\n",
      "progress 41.699999999999996 %\n",
      "progress 41.8 %\n",
      "progress 41.9 %\n",
      "progress 42.0 %\n",
      "progress 42.1 %\n",
      "progress 42.199999999999996 %\n",
      "progress 42.3 %\n",
      "progress 42.4 %\n",
      "progress 42.5 %\n",
      "progress 42.6 %\n",
      "progress 42.699999999999996 %\n",
      "progress 42.8 %\n",
      "progress 42.9 %\n",
      "progress 43.0 %\n",
      "progress 43.1 %\n",
      "progress 43.2 %\n",
      "progress 43.3 %\n",
      "progress 43.4 %\n",
      "progress 43.5 %\n",
      "progress 43.6 %\n",
      "progress 43.7 %\n",
      "progress 43.8 %\n",
      "progress 43.9 %\n",
      "progress 44.0 %\n",
      "progress 44.1 %\n",
      "progress 44.2 %\n",
      "progress 44.3 %\n",
      "progress 44.4 %\n",
      "progress 44.5 %\n",
      "progress 44.6 %\n",
      "progress 44.7 %\n",
      "progress 44.800000000000004 %\n",
      "progress 44.9 %\n",
      "progress 45.0 %\n",
      "progress 45.1 %\n",
      "progress 45.2 %\n",
      "progress 45.300000000000004 %\n",
      "progress 45.4 %\n",
      "progress 45.5 %\n",
      "progress 45.6 %\n",
      "progress 45.7 %\n",
      "progress 45.800000000000004 %\n",
      "progress 45.9 %\n",
      "progress 46.0 %\n",
      "progress 46.1 %\n",
      "progress 46.2 %\n",
      "progress 46.300000000000004 %\n",
      "progress 46.400000000000006 %\n",
      "progress 46.5 %\n",
      "progress 46.6 %\n",
      "progress 46.7 %\n",
      "progress 46.800000000000004 %\n",
      "progress 46.9 %\n",
      "progress 47.0 %\n",
      "progress 47.099999999999994 %\n",
      "progress 47.199999999999996 %\n",
      "progress 47.3 %\n",
      "progress 47.4 %\n",
      "progress 47.5 %\n",
      "progress 47.599999999999994 %\n",
      "progress 47.699999999999996 %\n",
      "progress 47.8 %\n",
      "progress 47.9 %\n",
      "progress 48.0 %\n",
      "progress 48.1 %\n",
      "progress 48.199999999999996 %\n",
      "progress 48.3 %\n",
      "progress 48.4 %\n",
      "progress 48.5 %\n",
      "progress 48.6 %\n",
      "progress 48.699999999999996 %\n",
      "progress 48.8 %\n",
      "progress 48.9 %\n",
      "progress 49.0 %\n",
      "progress 49.1 %\n",
      "progress 49.2 %\n",
      "progress 49.3 %\n",
      "progress 49.4 %\n",
      "progress 49.5 %\n",
      "progress 49.6 %\n",
      "progress 49.7 %\n",
      "progress 49.8 %\n",
      "progress 49.9 %\n",
      "progress 50.0 %\n",
      "progress 50.1 %\n",
      "progress 50.2 %\n",
      "progress 50.3 %\n",
      "progress 50.4 %\n",
      "progress 50.5 %\n",
      "progress 50.6 %\n",
      "progress 50.7 %\n",
      "progress 50.8 %\n",
      "progress 50.9 %\n",
      "progress 51.0 %\n",
      "progress 51.1 %\n",
      "progress 51.2 %\n",
      "progress 51.300000000000004 %\n",
      "progress 51.4 %\n",
      "progress 51.5 %\n",
      "progress 51.6 %\n",
      "progress 51.7 %\n",
      "progress 51.800000000000004 %\n",
      "progress 51.9 %\n",
      "progress 52.0 %\n",
      "progress 52.1 %\n",
      "progress 52.2 %\n",
      "progress 52.300000000000004 %\n",
      "progress 52.400000000000006 %\n",
      "progress 52.5 %\n",
      "progress 52.6 %\n",
      "progress 52.7 %\n",
      "progress 52.800000000000004 %\n",
      "progress 52.900000000000006 %\n",
      "progress 53.0 %\n",
      "progress 53.1 %\n",
      "progress 53.2 %\n",
      "progress 53.300000000000004 %\n",
      "progress 53.400000000000006 %\n",
      "progress 53.5 %\n",
      "progress 53.6 %\n",
      "progress 53.7 %\n",
      "progress 53.800000000000004 %\n",
      "progress 53.900000000000006 %\n",
      "progress 54.0 %\n",
      "progress 54.1 %\n",
      "progress 54.2 %\n",
      "progress 54.300000000000004 %\n",
      "progress 54.400000000000006 %\n",
      "progress 54.50000000000001 %\n",
      "progress 54.6 %\n",
      "progress 54.7 %\n",
      "progress 54.800000000000004 %\n",
      "progress 54.900000000000006 %\n",
      "progress 55.00000000000001 %\n",
      "progress 55.1 %\n",
      "progress 55.2 %\n",
      "progress 55.300000000000004 %\n",
      "progress 55.400000000000006 %\n",
      "progress 55.50000000000001 %\n",
      "progress 55.60000000000001 %\n",
      "progress 55.7 %\n",
      "progress 55.800000000000004 %\n",
      "progress 55.900000000000006 %\n",
      "progress 56.00000000000001 %\n",
      "progress 56.10000000000001 %\n",
      "progress 56.2 %\n",
      "progress 56.3 %\n",
      "progress 56.39999999999999 %\n",
      "progress 56.49999999999999 %\n",
      "progress 56.599999999999994 %\n",
      "progress 56.699999999999996 %\n",
      "progress 56.8 %\n",
      "progress 56.89999999999999 %\n",
      "progress 56.99999999999999 %\n",
      "progress 57.099999999999994 %\n",
      "progress 57.199999999999996 %\n",
      "progress 57.3 %\n",
      "progress 57.4 %\n",
      "progress 57.49999999999999 %\n",
      "progress 57.599999999999994 %\n",
      "progress 57.699999999999996 %\n",
      "progress 57.8 %\n",
      "progress 57.9 %\n",
      "progress 57.99999999999999 %\n",
      "progress 58.099999999999994 %\n",
      "progress 58.199999999999996 %\n",
      "progress 58.3 %\n",
      "progress 58.4 %\n",
      "progress 58.5 %\n",
      "progress 58.599999999999994 %\n",
      "progress 58.699999999999996 %\n",
      "progress 58.8 %\n",
      "progress 58.9 %\n",
      "progress 59.0 %\n",
      "progress 59.099999999999994 %\n",
      "progress 59.199999999999996 %\n",
      "progress 59.3 %\n",
      "progress 59.4 %\n",
      "progress 59.5 %\n",
      "progress 59.599999999999994 %\n",
      "progress 59.699999999999996 %\n",
      "progress 59.8 %\n",
      "progress 59.9 %\n",
      "progress 60.0 %\n",
      "progress 60.099999999999994 %\n",
      "progress 60.199999999999996 %\n",
      "progress 60.3 %\n",
      "progress 60.4 %\n",
      "progress 60.5 %\n",
      "progress 60.6 %\n",
      "progress 60.699999999999996 %\n",
      "progress 60.8 %\n",
      "progress 60.9 %\n",
      "progress 61.0 %\n",
      "progress 61.1 %\n",
      "progress 61.199999999999996 %\n",
      "progress 61.3 %\n",
      "progress 61.4 %\n",
      "progress 61.5 %\n",
      "progress 61.6 %\n",
      "progress 61.7 %\n",
      "progress 61.8 %\n",
      "progress 61.9 %\n",
      "progress 62.0 %\n",
      "progress 62.1 %\n",
      "progress 62.2 %\n",
      "progress 62.3 %\n",
      "progress 62.4 %\n",
      "progress 62.5 %\n",
      "progress 62.6 %\n",
      "progress 62.7 %\n",
      "progress 62.8 %\n",
      "progress 62.9 %\n",
      "progress 63.0 %\n",
      "progress 63.1 %\n",
      "progress 63.2 %\n",
      "progress 63.3 %\n",
      "progress 63.4 %\n",
      "progress 63.5 %\n",
      "progress 63.6 %\n",
      "progress 63.7 %\n",
      "progress 63.800000000000004 %\n",
      "progress 63.9 %\n",
      "progress 64.0 %\n",
      "progress 64.1 %\n",
      "progress 64.2 %\n",
      "progress 64.3 %\n",
      "progress 64.4 %\n",
      "progress 64.5 %\n",
      "progress 64.60000000000001 %\n",
      "progress 64.7 %\n",
      "progress 64.8 %\n",
      "progress 64.9 %\n",
      "progress 65.0 %\n",
      "progress 65.10000000000001 %\n",
      "progress 65.2 %\n",
      "progress 65.3 %\n",
      "progress 65.4 %\n",
      "progress 65.5 %\n",
      "progress 65.60000000000001 %\n",
      "progress 65.7 %\n",
      "progress 65.8 %\n",
      "progress 65.9 %\n",
      "progress 66.0 %\n",
      "progress 66.10000000000001 %\n",
      "progress 66.2 %\n",
      "progress 66.3 %\n",
      "progress 66.4 %\n",
      "progress 66.5 %\n",
      "progress 66.60000000000001 %\n",
      "progress 66.7 %\n",
      "progress 66.8 %\n",
      "progress 66.9 %\n",
      "progress 67.0 %\n",
      "progress 67.10000000000001 %\n",
      "progress 67.2 %\n",
      "progress 67.30000000000001 %\n",
      "progress 67.4 %\n",
      "progress 67.5 %\n",
      "progress 67.60000000000001 %\n",
      "progress 67.7 %\n",
      "progress 67.80000000000001 %\n",
      "progress 67.9 %\n",
      "progress 68.0 %\n",
      "progress 68.10000000000001 %\n",
      "progress 68.2 %\n",
      "progress 68.30000000000001 %\n",
      "progress 68.4 %\n",
      "progress 68.5 %\n",
      "progress 68.60000000000001 %\n",
      "progress 68.7 %\n",
      "progress 68.8 %\n",
      "progress 68.89999999999999 %\n",
      "progress 69.0 %\n",
      "progress 69.1 %\n",
      "progress 69.19999999999999 %\n",
      "progress 69.3 %\n",
      "progress 69.39999999999999 %\n",
      "progress 69.5 %\n",
      "progress 69.6 %\n",
      "progress 69.69999999999999 %\n",
      "progress 69.8 %\n",
      "progress 69.89999999999999 %\n",
      "progress 70.0 %\n",
      "progress 70.1 %\n",
      "progress 70.19999999999999 %\n",
      "progress 70.3 %\n",
      "progress 70.39999999999999 %\n",
      "progress 70.5 %\n",
      "progress 70.6 %\n",
      "progress 70.7 %\n",
      "progress 70.8 %\n",
      "progress 70.89999999999999 %\n",
      "progress 71.0 %\n",
      "progress 71.1 %\n",
      "progress 71.2 %\n",
      "progress 71.3 %\n",
      "progress 71.39999999999999 %\n",
      "progress 71.5 %\n",
      "progress 71.6 %\n",
      "progress 71.7 %\n",
      "progress 71.8 %\n",
      "progress 71.89999999999999 %\n",
      "progress 72.0 %\n",
      "progress 72.1 %\n",
      "progress 72.2 %\n",
      "progress 72.3 %\n",
      "progress 72.39999999999999 %\n",
      "progress 72.5 %\n",
      "progress 72.6 %\n",
      "progress 72.7 %\n",
      "progress 72.8 %\n",
      "progress 72.89999999999999 %\n",
      "progress 73.0 %\n",
      "progress 73.1 %\n",
      "progress 73.2 %\n",
      "progress 73.3 %\n",
      "progress 73.4 %\n",
      "progress 73.5 %\n",
      "progress 73.6 %\n",
      "progress 73.7 %\n",
      "progress 73.8 %\n",
      "progress 73.9 %\n",
      "progress 74.0 %\n",
      "progress 74.1 %\n",
      "progress 74.2 %\n",
      "progress 74.3 %\n",
      "progress 74.4 %\n",
      "progress 74.5 %\n",
      "progress 74.6 %\n",
      "progress 74.7 %\n",
      "progress 74.8 %\n",
      "progress 74.9 %\n",
      "progress 75.0 %\n",
      "progress 75.1 %\n",
      "progress 75.2 %\n",
      "progress 75.3 %\n",
      "progress 75.4 %\n",
      "progress 75.5 %\n",
      "progress 75.6 %\n",
      "progress 75.7 %\n",
      "progress 75.8 %\n",
      "progress 75.9 %\n",
      "progress 76.0 %\n",
      "progress 76.1 %\n",
      "progress 76.2 %\n",
      "progress 76.3 %\n",
      "progress 76.4 %\n",
      "progress 76.5 %\n",
      "progress 76.6 %\n",
      "progress 76.7 %\n",
      "progress 76.8 %\n",
      "progress 76.9 %\n",
      "progress 77.0 %\n",
      "progress 77.10000000000001 %\n",
      "progress 77.2 %\n",
      "progress 77.3 %\n",
      "progress 77.4 %\n",
      "progress 77.5 %\n",
      "progress 77.60000000000001 %\n",
      "progress 77.7 %\n",
      "progress 77.8 %\n",
      "progress 77.9 %\n",
      "progress 78.0 %\n",
      "progress 78.10000000000001 %\n",
      "progress 78.2 %\n",
      "progress 78.3 %\n",
      "progress 78.4 %\n",
      "progress 78.5 %\n",
      "progress 78.60000000000001 %\n",
      "progress 78.7 %\n",
      "progress 78.8 %\n",
      "progress 78.9 %\n",
      "progress 79.0 %\n",
      "progress 79.10000000000001 %\n",
      "progress 79.2 %\n",
      "progress 79.3 %\n",
      "progress 79.4 %\n",
      "progress 79.5 %\n",
      "progress 79.60000000000001 %\n",
      "progress 79.7 %\n",
      "progress 79.80000000000001 %\n",
      "progress 79.9 %\n",
      "progress 80.0 %\n",
      "progress 80.10000000000001 %\n",
      "progress 80.2 %\n",
      "progress 80.30000000000001 %\n",
      "progress 80.4 %\n",
      "progress 80.5 %\n",
      "progress 80.60000000000001 %\n",
      "progress 80.7 %\n",
      "progress 80.80000000000001 %\n",
      "progress 80.9 %\n",
      "progress 81.0 %\n",
      "progress 81.10000000000001 %\n",
      "progress 81.2 %\n",
      "progress 81.3 %\n",
      "progress 81.39999999999999 %\n",
      "progress 81.5 %\n",
      "progress 81.6 %\n",
      "progress 81.69999999999999 %\n",
      "progress 81.8 %\n",
      "progress 81.89999999999999 %\n",
      "progress 82.0 %\n",
      "progress 82.1 %\n",
      "progress 82.19999999999999 %\n",
      "progress 82.3 %\n",
      "progress 82.39999999999999 %\n",
      "progress 82.5 %\n",
      "progress 82.6 %\n",
      "progress 82.69999999999999 %\n",
      "progress 82.8 %\n",
      "progress 82.89999999999999 %\n",
      "progress 83.0 %\n",
      "progress 83.1 %\n",
      "progress 83.2 %\n",
      "progress 83.3 %\n",
      "progress 83.39999999999999 %\n",
      "progress 83.5 %\n",
      "progress 83.6 %\n",
      "progress 83.7 %\n",
      "progress 83.8 %\n",
      "progress 83.89999999999999 %\n",
      "progress 84.0 %\n",
      "progress 84.1 %\n",
      "progress 84.2 %\n",
      "progress 84.3 %\n",
      "progress 84.39999999999999 %\n",
      "progress 84.5 %\n",
      "progress 84.6 %\n",
      "progress 84.7 %\n",
      "progress 84.8 %\n",
      "progress 84.89999999999999 %\n",
      "progress 85.0 %\n",
      "progress 85.1 %\n",
      "progress 85.2 %\n",
      "progress 85.3 %\n",
      "progress 85.39999999999999 %\n",
      "progress 85.5 %\n",
      "progress 85.6 %\n",
      "progress 85.7 %\n",
      "progress 85.8 %\n",
      "progress 85.9 %\n",
      "progress 86.0 %\n",
      "progress 86.1 %\n",
      "progress 86.2 %\n",
      "progress 86.3 %\n",
      "progress 86.4 %\n",
      "progress 86.5 %\n",
      "progress 86.6 %\n",
      "progress 86.7 %\n",
      "progress 86.8 %\n",
      "progress 86.9 %\n",
      "progress 87.0 %\n",
      "progress 87.1 %\n",
      "progress 87.2 %\n",
      "progress 87.3 %\n",
      "progress 87.4 %\n",
      "progress 87.5 %\n",
      "progress 87.6 %\n",
      "progress 87.7 %\n",
      "progress 87.8 %\n",
      "progress 87.9 %\n",
      "progress 88.0 %\n",
      "progress 88.1 %\n",
      "progress 88.2 %\n",
      "progress 88.3 %\n",
      "progress 88.4 %\n",
      "progress 88.5 %\n",
      "progress 88.6 %\n",
      "progress 88.7 %\n",
      "progress 88.8 %\n",
      "progress 88.9 %\n",
      "progress 89.0 %\n",
      "progress 89.1 %\n",
      "progress 89.2 %\n",
      "progress 89.3 %\n",
      "progress 89.4 %\n",
      "progress 89.5 %\n",
      "progress 89.60000000000001 %\n",
      "progress 89.7 %\n",
      "progress 89.8 %\n",
      "progress 89.9 %\n",
      "progress 90.0 %\n",
      "progress 90.10000000000001 %\n",
      "progress 90.2 %\n",
      "progress 90.3 %\n",
      "progress 90.4 %\n",
      "progress 90.5 %\n",
      "progress 90.60000000000001 %\n",
      "progress 90.7 %\n",
      "progress 90.8 %\n",
      "progress 90.9 %\n",
      "progress 91.0 %\n",
      "progress 91.10000000000001 %\n",
      "progress 91.2 %\n",
      "progress 91.3 %\n",
      "progress 91.4 %\n",
      "progress 91.5 %\n",
      "progress 91.60000000000001 %\n",
      "progress 91.7 %\n",
      "progress 91.8 %\n",
      "progress 91.9 %\n",
      "progress 92.0 %\n",
      "progress 92.10000000000001 %\n",
      "progress 92.2 %\n",
      "progress 92.30000000000001 %\n",
      "progress 92.4 %\n",
      "progress 92.5 %\n",
      "progress 92.60000000000001 %\n",
      "progress 92.7 %\n",
      "progress 92.80000000000001 %\n",
      "progress 92.9 %\n",
      "progress 93.0 %\n",
      "progress 93.10000000000001 %\n",
      "progress 93.2 %\n",
      "progress 93.30000000000001 %\n",
      "progress 93.4 %\n",
      "progress 93.5 %\n",
      "progress 93.60000000000001 %\n",
      "progress 93.7 %\n",
      "progress 93.8 %\n",
      "progress 93.89999999999999 %\n",
      "progress 94.0 %\n",
      "progress 94.1 %\n",
      "progress 94.19999999999999 %\n",
      "progress 94.3 %\n",
      "progress 94.39999999999999 %\n",
      "progress 94.5 %\n",
      "progress 94.6 %\n",
      "progress 94.69999999999999 %\n",
      "progress 94.8 %\n",
      "progress 94.89999999999999 %\n",
      "progress 95.0 %\n",
      "progress 95.1 %\n",
      "progress 95.19999999999999 %\n",
      "progress 95.3 %\n",
      "progress 95.39999999999999 %\n",
      "progress 95.5 %\n",
      "progress 95.6 %\n",
      "progress 95.7 %\n",
      "progress 95.8 %\n",
      "progress 95.89999999999999 %\n",
      "progress 96.0 %\n",
      "progress 96.1 %\n",
      "progress 96.2 %\n",
      "progress 96.3 %\n",
      "progress 96.39999999999999 %\n",
      "progress 96.5 %\n",
      "progress 96.6 %\n",
      "progress 96.7 %\n",
      "progress 96.8 %\n",
      "progress 96.89999999999999 %\n",
      "progress 97.0 %\n",
      "progress 97.1 %\n",
      "progress 97.2 %\n",
      "progress 97.3 %\n",
      "progress 97.39999999999999 %\n",
      "progress 97.5 %\n",
      "progress 97.6 %\n",
      "progress 97.7 %\n",
      "progress 97.8 %\n",
      "progress 97.89999999999999 %\n",
      "progress 98.0 %\n",
      "progress 98.1 %\n",
      "progress 98.2 %\n",
      "progress 98.3 %\n",
      "progress 98.4 %\n",
      "progress 98.5 %\n",
      "progress 98.6 %\n",
      "progress 98.7 %\n",
      "progress 98.8 %\n",
      "progress 98.9 %\n",
      "progress 99.0 %\n",
      "progress 99.1 %\n",
      "progress 99.2 %\n",
      "progress 99.3 %\n",
      "progress 99.4 %\n",
      "progress 99.5 %\n",
      "progress 99.6 %\n",
      "progress 99.7 %\n",
      "progress 99.8 %\n",
      "progress 99.9 %\n",
      "progress 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# explainer = lime.lime_tabular.LimeTabularExplainer(test, feature_names= list(test2.columns.values) , class_names=label , discretize_continuous=True)\n",
    "\n",
    "#creating dict \n",
    "feat_list = ['L4_DST_PORT','TCP_WIN_MSS_IN',\n",
    "                            'OUT_PKTS','IN_PKTS', 'FLOW_DURATION_MILLISECONDS',\n",
    "                            'unrelated_column']\n",
    "# print(feat_list)\n",
    "\n",
    "# feat_dict = dict.fromkeys(feat_list, 0)\n",
    "c = 0\n",
    "\n",
    "num_columns = len(feat_list)\n",
    "feature_name = feat_list\n",
    "feature_name_2 = feat_list\n",
    "feature_name_2.sort()\n",
    "feature_name.sort()\n",
    "feature_val = []\n",
    "feature_val_2 = []\n",
    "feature_val_abs = []\n",
    "feature_val_abs_2 = []\n",
    "\n",
    "# position = y_labels.index(rf.predict(Dos_sample2))\n",
    "# position =  np.argmax(rf.predict_proba(((Dos_sample2))))\n",
    "# print(len(y_labels))\n",
    "# print(rf.predict(Dos_sample2))\n",
    "\n",
    "\n",
    "# sample = Dos_sample\n",
    "# samples = 1 \n",
    "# sample = PS_sample\n",
    "\n",
    "\n",
    "for i in range(0,num_columns): \n",
    "    feature_val.append(0)\n",
    "    feature_val_abs.append(0)\n",
    "    feature_val_2.append(0)\n",
    "    feature_val_abs_2.append(0)    \n",
    "\n",
    "# # i = sample\n",
    "#     # exp = explainer.explain_instance(test[i], rf.predict_proba)\n",
    "\n",
    "#     exp = explainer.explain_instance(sample, rf.predict_proba, num_features=num_columns, top_labels=len(y_labels))\n",
    "#     exp.show_in_notebook(show_table=True, show_all=True)\n",
    "# Let's just look at a the first example in the test set\n",
    "# ex_indc = np.random.choice(xtest.shape[0])\n",
    "\n",
    "# samples = xtest.shape[0]\n",
    "samples = 1000\n",
    "\n",
    "for k in range(0,samples):\n",
    "    ex_indc = k\n",
    "    # print(xtest.shape[0])\n",
    "    # indices = np.where(ytest == 1)\n",
    "    # index_positions = indices[0]\n",
    "    # print(index_positions)\n",
    "    # ex_indc = index_positions[0]\n",
    "    # To get a baseline, we'll look at LIME applied to the biased model f\n",
    "    normal_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(),\n",
    "                                                        discretize_continuous=False,\n",
    "                                                        categorical_features=categorical_feature_indcs)\n",
    "\n",
    "    normal_exp = normal_explainer.explain_instance(xtest[ex_indc], racist_model_f().predict_proba).as_list()\n",
    "\n",
    "    # print('------------------------------------------------------------------')\n",
    "    # print('real value', ytest[ex_indc:ex_indc+1])\n",
    "    # print(ytest)\n",
    "    # print('------------------------------------------------------------------')\n",
    "    # print('------------------------------------------------------------------')\n",
    "    # print(xtest[ex_indc])\n",
    "    # print(xtest)\n",
    "    # print('predicted value', racist_model_f().predict(xtest)[ex_indc])\n",
    "\n",
    "    # print('------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    # pred = racist_model_f().predict_proba(xtest[ex_indc])                             \n",
    "    # print('prediction', pred)\n",
    "    # print (\"Explanation on biased f:\\n\",normal_exp[:3],\"\\n\\n\")\n",
    "\n",
    "    # Now, lets look at the explanations on the adversarial model \n",
    "    adv_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(), \n",
    "                                                    discretize_continuous=False,\n",
    "                                                    categorical_features=categorical_feature_indcs)\n",
    "\n",
    "    adv_exp = adv_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba).as_list()\n",
    "\n",
    "    # print (\"Explanation on adversarial model:\\n\",adv_exp[:3],\"\\n\")\n",
    "\n",
    "    # print(\"Prediction fidelity: {0:3.2}\".format(adv_lime.fidelity(xtest[ex_indc:ex_indc+1])))\n",
    "\n",
    "    lime_list = adv_exp\n",
    "    lime_list_2 = normal_exp\n",
    "    lime_list.sort()\n",
    "    lime_list_2.sort()\n",
    "    # print(lime_list)\n",
    "\n",
    "    for i in range(0,len(lime_list)):\n",
    "    #---------------------------------------------------\n",
    "    #fix\n",
    "        my_string = lime_list[i][0]\n",
    "        for index, char in enumerate(my_string):\n",
    "            if char.isalpha():\n",
    "                first_letter_index = index\n",
    "                break  # Exit the loop when the first letter is found\n",
    "        my_string = my_string[first_letter_index:]\n",
    "        modified_tuple = list(lime_list[i])\n",
    "        modified_tuple[0] = my_string\n",
    "        lime_list[i] = tuple(modified_tuple)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,len(lime_list_2)):\n",
    "    #---------------------------------------------------\n",
    "    #fix\n",
    "        my_string_2 = lime_list_2[i][0]\n",
    "        for index, char in enumerate(my_string_2):\n",
    "            if char.isalpha():\n",
    "                first_letter_index_2 = index\n",
    "                break  # Exit the loop when the first letter is found  \n",
    "        my_string_2 = my_string_2[first_letter_index_2:]\n",
    "        modified_tuple_2 = list(lime_list_2[i])\n",
    "        modified_tuple_2[0] = my_string_2\n",
    "        lime_list_2[i] = tuple(modified_tuple_2)\n",
    "            \n",
    "    #---------------------------------------------------\n",
    "\n",
    "    lime_list.sort()\n",
    "    lime_list_2.sort()\n",
    "    # print(lime_list)\n",
    "    # for j in range (0,num_columns): feature_val[j]+= abs(lime_list[j][1])\n",
    "    for j in range (0,num_columns):feature_val_abs[j] = abs(lime_list[j][1])\n",
    "    for j in range (0,num_columns):feature_val_abs_2[j] = abs(lime_list_2[j][1])\n",
    "    for j in range (0,num_columns):feature_val[j] = lime_list[j][1]\n",
    "    for j in range (0,num_columns):feature_val_2[j] = lime_list_2[j][1]\n",
    "    c = c + 1 \n",
    "    print ('progress',100*(c/samples),'%')\n",
    "\n",
    "\n",
    "\n",
    "    # Define the number you want to divide by\n",
    "    # divider = samples\n",
    "\n",
    "    # Use a list comprehension to divide all elements by the same number\n",
    "    # feature_val = [x / divider for x in feature_val]\n",
    "    # feature_val_2 = [x / divider for x in feature_val_2]\n",
    "\n",
    "    # for item1, item2 in zip(feature_name, feature_val):\n",
    "    #     print(item1, item2)\n",
    "\n",
    "\n",
    "    # Use zip to combine the two lists, sort based on list1, and then unzip them\n",
    "    zipped_lists = list(zip(feature_name, feature_val,feature_val_abs))\n",
    "    zipped_lists.sort(key=lambda x: x[2],reverse=True)\n",
    "\n",
    "    zipped_lists_2 = list(zip(feature_name_2, feature_val_2,feature_val_abs_2))\n",
    "    zipped_lists_2.sort(key=lambda x: x[2],reverse=True)\n",
    "\n",
    "    # Convert the sorted result back into separate lists\n",
    "    sorted_list1, sorted_list2,sorted_list3 = [list(x) for x in zip(*zipped_lists)]\n",
    "\n",
    "    sorted_list1_2, sorted_list2_2,sorted_list3_2 = [list(x) for x in zip(*zipped_lists_2)]\n",
    "\n",
    "    # print('Adversarial')\n",
    "    # print(sorted_list1)\n",
    "    # print(sorted_list2)\n",
    "    # print(sorted_list3)\n",
    "\n",
    "    # print('Biased')\n",
    "    # print('----------------------------------------------------------------------------------------------------------------')\n",
    "    # print(sorted_list1_2)\n",
    "    # print(sorted_list2_2)\n",
    "    # print(sorted_list3_2)\n",
    "    # print('----------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "    biased_df = pd.DataFrame({\n",
    "            'shap_values': sorted_list2_2,\n",
    "            'shap_values_abs': sorted_list3_2,\n",
    "            'features': sorted_list1_2  \n",
    "        })\n",
    "    attack1_df = pd.DataFrame({\n",
    "            'shap_values': sorted_list2 ,\n",
    "            'shap_values_abs':sorted_list3,\n",
    "            'features':  sorted_list1  \n",
    "        })\n",
    "    # info = [adv_shap_values,features]\n",
    "\n",
    "    attack1_df.sort_values(by=['shap_values_abs'], ascending=False,inplace=True)\n",
    "    biased_df.sort_values(by=['shap_values_abs'], ascending=False,inplace=True)\n",
    "\n",
    "    attack1_df = attack1_df.reset_index(drop=True)\n",
    "    biased_df = biased_df.reset_index(drop=True)\n",
    "\n",
    "    # print('Attack')\n",
    "    # print('------------------------------')\n",
    "    # print (attack1_df)\n",
    "    # print('Biased')\n",
    "    # print('------------------------------')\n",
    "    # print(biased_df)\n",
    "\n",
    "\n",
    "    #biased columns\n",
    "\n",
    "    #For 1st position\n",
    "    # print(biased_df['shap_values'][0] )\n",
    "    if biased_df['features'][0] == biased_feature: dict_biased_1['Biased'] = dict_biased_1['Biased'] + 1\n",
    "    elif biased_df['features'][0] == Unrelated_1_feature: dict_biased_1['Unrelated_1'] = dict_biased_1['Unrelated_1'] + 1\n",
    "    # elif biased_df['features'][0] == Unrelated_2_feature: dict_biased_1['Unrelated_2'] = dict_biased_1['Unrelated_2'] + 1\n",
    "    else: dict_biased_1['Others'] = dict_biased_1['Others'] + 1\n",
    "\n",
    "    #For 2st position\n",
    "    if biased_df['features'][1] == biased_feature: dict_biased_2['Biased'] = dict_biased_2['Biased'] + 1\n",
    "    elif biased_df['features'][1] == Unrelated_1_feature: dict_biased_2['Unrelated_1'] = dict_biased_2['Unrelated_1'] + 1\n",
    "    # elif biased_df['features'][1] == Unrelated_2_feature: dict_biased_2['Unrelated_2'] = dict_biased_2['Unrelated_2'] + 1\n",
    "    else: dict_biased_2['Others'] = dict_biased_2['Others'] + 1\n",
    "\n",
    "    #For 3st position\n",
    "    if biased_df['features'][2] == biased_feature: dict_biased_3['Biased'] = dict_biased_3['Biased'] + 1\n",
    "    elif biased_df['features'][2] == Unrelated_1_feature: dict_biased_3['Unrelated_1'] = dict_biased_3['Unrelated_1'] + 1\n",
    "    # elif biased_df['features'][2] == Unrelated_2_feature: dict_biased_3['Unrelated_2'] = dict_biased_3['Unrelated_2'] + 1\n",
    "    else: dict_biased_3['Others'] = dict_biased_3['Others'] + 1\n",
    "\n",
    "\n",
    "    #Attack 1 columns\n",
    "\n",
    "    #For 1st position\n",
    "    if attack1_df['features'][0] == biased_feature: attack_1['Biased'] = attack_1['Biased'] + 1\n",
    "    elif attack1_df['features'][0] == Unrelated_1_feature: attack_1['Unrelated_1'] = attack_1['Unrelated_1'] + 1\n",
    "    # elif attack1_df['features'][0] == Unrelated_2_feature: attack_1['Unrelated_2'] = attack_1['Unrelated_2'] + 1\n",
    "    else: attack_1['Others'] = attack_1['Others'] + 1\n",
    "\n",
    "    #For 2st position\n",
    "    if attack1_df['features'][1] == biased_feature: attack_2['Biased'] = attack_2['Biased'] + 1\n",
    "    elif attack1_df['features'][1] == Unrelated_1_feature: attack_2['Unrelated_1'] = attack_2['Unrelated_1'] + 1\n",
    "    # elif attack1_df['features'][1] == Unrelated_2_feature: attack_2['Unrelated_2'] = attack_2['Unrelated_2'] + 1\n",
    "    else: attack_2['Others'] = attack_2['Others'] + 1\n",
    "\n",
    "    #For 3st position\n",
    "    if attack1_df['features'][2] == biased_feature: attack_3['Biased'] = attack_3['Biased'] + 1\n",
    "    elif attack1_df['features'][2] == Unrelated_1_feature: attack_3['Unrelated_1'] = attack_3['Unrelated_1'] + 1\n",
    "    # elif attack1_df['features'][2] == Unrelated_2_feature: attack_3['Unrelated_2'] = attack_3['Unrelated_2'] + 1\n",
    "    else: attack_3['Others'] = attack_3['Others'] + 1\n",
    "\n",
    "# for item1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Biased': 982, 'Unrelated_1': 0, 'Unrelated_2': 0, 'Others': 18}\n",
      "{'Biased': 5, 'Unrelated_1': 94, 'Unrelated_2': 0, 'Others': 901}\n",
      "{'Biased': 13, 'Unrelated_1': 191, 'Unrelated_2': 0, 'Others': 796}\n",
      "--------------\n",
      "{'Biased': 0, 'Unrelated_1': 1000, 'Unrelated_2': 0, 'Others': 0}\n",
      "{'Biased': 9, 'Unrelated_1': 0, 'Unrelated_2': 0, 'Others': 991}\n",
      "{'Biased': 36, 'Unrelated_1': 0, 'Unrelated_2': 0, 'Others': 964}\n"
     ]
    }
   ],
   "source": [
    "print(dict_biased_1 )\n",
    "print(dict_biased_2 )\n",
    "print(dict_biased_3 )\n",
    "print('--------------')\n",
    "print(attack_1 )\n",
    "print(attack_2 )\n",
    "print(attack_3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME Results\n",
    "What we have is the top three features of the explanation on the biased model followed by the explanation on that same instance using the adversarial model. We see that the top feature is now the randomly drawn column, indicating that the attack was able to fool LIME. We also see that the adversarial model predicts this instance _the same_ as the biased model (fidelity=1)—although the model predicts the same results, its reasoning has changed.\n",
    "\n",
    "Next, let's look at the SHAP adversarial model.  We'll go through a similar process as above except using SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized\n",
    "keys = ['Biased','Unrelated_1','Unrelated_2','Others' ]\n",
    "for x in keys:\n",
    "\n",
    "    dict_biased_1[x] = dict_biased_1[x]/samples\n",
    "    dict_biased_2[x] = dict_biased_2[x]/samples\n",
    "    dict_biased_3[x] = dict_biased_3[x]/samples\n",
    "\n",
    "    attack_1[x] = attack_1[x]/samples\n",
    "    attack_2[x] = attack_2[x]/samples\n",
    "    attack_3[x] = attack_3[x]/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing package\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "total = samples \n",
    "# create data\n",
    "x = ['1st', '2nd', '3rd']\n",
    "y1 = np.array([dict_biased_1['Biased'], dict_biased_2['Biased'], dict_biased_3['Biased']])\n",
    "y2 = np.array([dict_biased_1['Unrelated_1'], dict_biased_2['Unrelated_1'], dict_biased_3['Unrelated_1']])\n",
    "y3 = np.array([dict_biased_1['Others'], dict_biased_2['Others'], dict_biased_3['Others']])\n",
    "y4 = np.array([dict_biased_1['Unrelated_2'], dict_biased_2['Unrelated_2'],dict_biased_3['Unrelated_2']])\n",
    "\n",
    "\n",
    "# plot bars in stack manner\n",
    "plt.bar(x, y1, color='r')\n",
    "plt.bar(x, y2, bottom=y1, color='b')\n",
    "plt.bar(x, y3, bottom=y1+y2, color='grey')\n",
    "# plt.bar(x, y4, bottom=y1+y2+y3, color='g')\n",
    "plt.xlabel(\"Features Importance Rank\", fontsize = 18)\n",
    "plt.ylabel(\"% Ocurrence\", fontsize = 18)\n",
    "# plt.legend([\"Biased\", \"Unrelated\", \"Unrelated_2\", \"Others\"])\n",
    "plt.legend([\"Biased\", \"Unrelated\", \"Others\"], fontsize = 14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing package\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "total = samples \n",
    "# create data\n",
    "x = ['1st', '2nd', '3rd']\n",
    "y1 = np.array([attack_1['Biased'], attack_2['Biased'], attack_3['Biased']])\n",
    "y2 = np.array([attack_1['Unrelated_1'], attack_2['Unrelated_1'], attack_3['Unrelated_1']])\n",
    "y3 = np.array([attack_1['Others'], attack_2['Others'],attack_3['Others']])\n",
    "# y4 = np.array([attack_1['Unrelated_2'], attack_2['Unrelated_2'], attack_3['Unrelated_2']])\n",
    "\n",
    "# plot bars in stack manner\n",
    "plt.bar(x, y1, color='r')\n",
    "plt.bar(x, y2, bottom=y1, color='b')\n",
    "plt.bar(x, y3, bottom=y1+y2, color='grey')\n",
    "# plt.bar(x, y4, bottom=y1+y2+y3, color='g')\n",
    "plt.xlabel(\"Features Importance Rank\", fontsize = 18)\n",
    "plt.ylabel(\"% Ocurrence\", fontsize = 18)\n",
    "# plt.legend([\"Biased\", \"Unrelated_1\", \"Unrelated_2\", \"Others\"])\n",
    "plt.legend([\"Biased\", \"Unrelated_1\", \"Others\"], fontsize = 14)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HITL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
